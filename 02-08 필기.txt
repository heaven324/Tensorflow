★ cifar10 이미지 데이터를 신경망으로 로드하는 함수 생성

	1. 데이터를 신경망으로 로드하는 데이터 전처리 코드 
		인터넷으로 찾기 어려우므로 자신이 직접 짜야한다.
		- 훈련 이미지 데이터를 numpy array 숫자로 변환
       		- 훈련 이미지의 라벨을 one hot encoding 하는 방법



	2. 신경망 코드 <------- 인터넷에서 쉽게 구할 수 있는 코드











★ 훈련 이미지의 라벨을 one hot encoding 하는 방법



문제 52. test_label.csv 파일을 J:\\a\\cifar10 밑에 복사하고 결과가 아래와 같이 출력될 수 있도록 함수를 
	 생성하시오

	test_image = "c:\\a\\cifar10\\test"
	test_label = "c:\\a\\cifar10\\test_label.csv"
	
	import os
	import numpy as np
	import csv
	
	def label_load(path):
	    file = open(path)
	    labeldata = csv.reader(file)
	    labellist = []
	    for i in labeldata:
	        labellist.append(i)
	    return labellist
	print( label_load(test_label) )






문제 53. 위의 숫자 list 를 numpy 배열로 변환하시오 !

	test_image = "c:\\a\\cifar10\\test"
	test_label = "c:\\a\\cifar10\\test_label.csv"
	
	import os
	import numpy as np
	import csv
	
	def label_load(path):
	    file = open(path)
	    labeldata = csv.reader(file)
	    labellist = []
	    for i in labeldata:
	        labellist.append(i)
	    labellist = np.array(labellist)
	    return labellist
	
	print( label_load(test_label) )






문제 54. 위의 결과가 문자가 아니라 숫자로 출력되게 변환하시오 !


	test_image = "c:\\a\\cifar10\\test"
	test_label = "c:\\a\\cifar10\\test_label.csv"
	
	import os
	import numpy as np
	import csv
	
	def label_load(path):
	    file = open(path)
	    labeldata = csv.reader(file)
	    labellist = []
	    for i in labeldata:
	        labellist.append(i)
	    labellist = np.array(labellist).astype(int)
	    return labellist
	
	print( label_load(test_label) )






문제 55. 아래의 결과를 출력하시오 !

	import numpy as np
	
	print(np.eye(10)[4])






문제 56. 문제 54번에서 가져온 숫자리스트를 가지고 아래와 같이 one hot encoding된 결과를 
	 출력하시오 !

	test_image = "c:\\a\\cifar10\\test"
	test_label = "c:\\a\\cifar10\\test_label.csv"
	
	import os
	import numpy as np
	import csv
	
	def label_load(path):
	    file = open(path)
	    labeldata = csv.reader(file)
	    labellist = []
	    for i in labeldata:
	        labellist.append(i)
	    labellist = np.array(labellist).astype(int)
	    labellist = np.eye(10)[labellist]
	    return labellist
	
	print( label_load(test_label).shape )





문제 57. 위의 차원은 3차원인데 우리는 2차원으로 줄여야 한다. 왜냐하면 cnn코드에서 라벨이 입력될 때는 
	 아래처럼 2차원이기 때문이다.

	test_image = "c:\\a\\cifar10\\test"
	test_label = "c:\\a\\cifar10\\test_label.csv"
	
	import os
	import numpy as np
	import csv
	
	def label_load(path):
	    file = open(path)
	    labeldata = csv.reader(file)
	    labellist = []
	    for i in labeldata:
	        labellist.append(i)
	    labellist = np.array(labellist).astype(int)
	    labellist = np.eye(10)[labellist]
	    return np.squeeze(labellist)
	
	print( label_load(test_label).shape )





문제 58. 지금까지 만든 두가지 함수 image_load,label_load를 loader2.py라는 파이썬 코드에 저장하고 아래와 
	 같이 loader2.py를 import 한후에 cifar10전체 데이터를 로드하는 코드를 구현하시오 !

	import  loader2
	import time
	
	train_image = 'c:\\a\\cifar10\\train\\'
	train_label = 'c:\\a\\cifar10\\train_label.csv'
	test_image = 'c:\\a\\cifar10\\test\\'
	test_label = 'c:\\a\\cifar10\\test_label.csv'
	
	print("LOADING DATA")
	start = time.time()
	trainX = loader2.image_load(train_image)
	print(trainX.shape) # (50000, 32, 32,3)
	trainY = loader2.label_load(train_label)
	print(trainY.shape) # (50000, 10)
	testX = loader2.image_load(test_image)
	print(testX.shape) # (10000,32, 32, 3)
	testY = loader2.label_load(test_label)
	print(testY.shape) # (10000, 10)













■ 이미지를 신경망에 로드하기 위해 만들어야 하는 함수 4가지

	  1. image_load     : 훈련 이미지와 테스트 이미지 로드하는 함수
	  2. label_load        : 훈련 라벨과 테스트 라벨을 로드하는 함수
	  3. next_batch      : 훈련 이미지 데이터를 100개씩 신경망에 입력하는 함수
	  4. shuffle_batch : data를 shuffle하는 함수

	예 :
	trainX=loader2.image_load(train_image)         
	trainY=loader2.label_load(train_label)
	testX=loader2.image_load(test_image)         
	testY=loader2.label_load(test_label)





문제 59. test100폴더 밑에 10000개의 데이터중 100개만 출력하시오 !

	import os
	import numpy as np
	import csv
	import loader2
	
	test_image='c:\\a\\cifar10\\test'
	trainX=loader2.image_load(test_image)
	
	print(trainX[0:100])
	print(trainX[100:200])





문제 60. next_batch함수를 만들어서 아래와 같이 데이터를 입력하고 함수를 실행하면 trainX에서 100개의 
	 데이터(numpy 배열)을 가져오게 하시오 !

	import os
	import numpy as np
	import csv
	import loader2
	
	test_image='c:\\a\\cifar10\\test'
	trainX=loader2.image_load(test_image)
	
	def next_batch(img, start, finish):
	    return img[start:finish]
	
	print(next_batch(trainX, 0, 100).shape)





문제 61. 이번에는 라벨도 배치 사이즈 만큼 같이 출력될 수 있도록 next_batch함수에 코드를 추가해서 아래와 
	 같이 출력되게 하시오 !

	import os
	import numpy as np
	import csv
	import loader2
	
	def next_batch(img, label, start, finish):
	    return img[start:finish], label[start:finish]
	
	train_image = 'c:\\a\\cifar10\\train\\'
	train_label = 'c:\\a\\cifar10\\train_label.csv'
	test_image = 'c:\\a\\cifar10\\test\\'
	test_label = 'c:\\a\\cifar10\\test_label.csv'
	
	print("LOADING DATA")
	trainX = loader2.image_load(train_image)
	trainY = loader2.label_load(train_label)
	
	x, y = next_batch(trainX, trainY, 0, 100)
	print(x)
	print(y)





문제 62. 아래의 코드를 실행해 보시오 !

	import random
	import numpy as np
	print( np.arange(10))

	[0 1 2 3 4 5 6 7 8 9]




문제 63. 위의 숫자 10개가 랜덤으로 섞여서 출력되게 하시오 !
	 (random.shuffle을 사용해서 구현하시오 !)

	import random
	import numpy as np
	x = np.arange(10)
	random.shuffle(x)
	print(x)
	
	[4 2 6 8 7 0 9 1 5 3]






문제 64. 위의 코드를 이용해서 shuffle_batch함수를 만들어서 입력된 데이터가 shuffle되게 하시오 !

	import random
	import numpy as np
	import  loader2
	
	train_image = 'c:\\a\\cifar10\\train\\'
	train_label = 'c:\\a\\cifar10\\train_label.csv'
	test_image = 'c:\\a\\cifar10\\test\\'
	test_label = 'c:\\a\\cifar10\\test_label.csv'
	
	print("LOADING DATA")
	start = time.time()
	testX = loader2.image_load(test_image)
	testY = loader2.label_load(test_label)
	print(testX)
	print(testY)
	def shuffle_batch(dataa, datab):
	    x = np.arange(len(dataa))
	    random.shuffle(x)
	    data_list2 = dataa[x]
	    label2 = datab[x]
	    return data_list2, label2
	
	x, y = shuffle_batch(testX, testY)
	print(x)
	print(y)





문제 66. 기존 mnist 데이터를 텐써 플로우로 만든 cnn신경망에 입력하는 코드를 가져와서 mnist 대신에 
	 cifar10 데이터를 입력해서 학습 시키고 정확도 그래프를 볼 수 있도록 코드를 완성시키시오.


trainX = loader2.image_load(train_image)
print(trainX.shape) # (50000, 32, 32,3)
trainY = loader2.label_load(train_label)
print(trainY.shape) # (50000, 10)
testX = loader2.image_load(test_image)
print(testX.shape) # (10000,32, 32, 3)
testY = loader2.label_load(test_label)
print(testY.shape) # (10000, 10)









★ cifar10 신경망 구현
	1. cifar10데이터로 Vgg신경망 구현 훈련 정확도 93% 테스트 정확도 89%











■ 이미지넷 대회에서 우승한 신경망을 구현 
	1. Vggnet
	2. Googlelenet(인셉션)
	3. Resnet








문제 65. 기존 mnist 데이터를 텐써 플로우로 만든 cnn신경망에 입력하는 코드를 가져와서 mnist 대신에 cifar10 
	 데이터를 입력해서 학습 시키고 정확도 그래프를 볼 수 있도록 코드를 완성시키시오.

import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import matplotlib.pyplot as plt
import numpy as np
import loader2

#데이터 로드 그리고 한번에 셔플
train_image = 'c:\\a\\cifar10\\train\\'
train_label = 'c:\\a\\cifar10\\train_label.csv'
test_image = 'c:\\a\\cifar10\\test\\'
test_label = 'c:\\a\\cifar10\\test_label.csv'

print("LOADING DATA")
trainX = loader2.image_load(train_image)
trainY = loader2.label_load(train_label)
testX = loader2.image_load(test_image)
testY = loader2.label_load(test_label)

trainX, trainY = loader2.shuffle_batch(trainX, trainY)
testX, testY = loader2.shuffle_batch(testX, testY)



# 입력층
tf.reset_default_graph()
x_load = tf.placeholder("float", [None, 32, 32, 3])
z_onehot = tf.placeholder("float", [None, 10])
z_label = tf.argmax(z_onehot, axis = 1)
keep_prob = tf.placeholder("float")



# 은닉 1층
W1 = tf.get_variable(name='W1', shape=[3, 3, 3, 32], \
                     initializer=tf.contrib.layers.variance_scaling_initializer())
b1 = tf.Variable(tf.ones([32, 32, 32]))

x = tf.nn.conv2d(x_load, W1, strides=[1, 1, 1, 1], padding = 'SAME')
x = tf.nn.relu(x) + b1
x = tf.nn.max_pool(x, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')
# x = tf.reshape(x, [-1, 6272])



# 은닉 2층
W2 = tf.get_variable(name='W2', shape=[3, 3, 32, 64], \
                     initializer=tf.contrib.layers.variance_scaling_initializer())
b2 = tf.Variable(tf.ones([16, 16, 64]))

x1 = tf.nn.conv2d(x, W2, strides=[1, 1, 1, 1], padding = 'SAME')
x1 = tf.nn.relu(x1) + b2
x1 = tf.nn.max_pool(x1, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')
x1 = tf.reshape(x1, [-1, 4096])



# 은닉 3층
W3 = tf.get_variable(name='W3', shape=[4096, 100], \
                     initializer=tf.contrib.layers.variance_scaling_initializer())
b3 = tf.Variable(tf.ones([100]))

y = tf.matmul(x1, W3) + b3
y = tf.contrib.layers.batch_norm(y,True)
y = tf.nn.relu(y)
y = tf.nn.dropout(y, keep_prob)



# 은닉 3층
W4 = tf.get_variable(name='W4', shape=[100, 100], \
                     initializer=tf.contrib.layers.variance_scaling_initializer())
b4 = tf.Variable(tf.ones([100]))

y1 = tf.matmul(y, W4) + b4
y1 = tf.nn.relu(y1)
y1 = tf.nn.dropout(y1, keep_prob)



# 출력층(4층)
W5 = tf.get_variable(name='W5', shape=[100, 10], \
                     initializer=tf.contrib.layers.variance_scaling_initializer())
b5 = tf.Variable(tf.ones([10]))

z = tf.matmul(y1, W5) + b5
z_hat = tf.nn.softmax(z)
z = tf.argmax(z_hat, axis = 1)



correction_prediction = tf.equal(z, z_label)
accuracy = tf.reduce_mean(tf.cast(correction_prediction, "float"))
loss = - tf.reduce_sum(z_onehot*tf.log(z_hat), axis = 1)
optimizer = tf.train.AdamOptimizer(learning_rate=0.001)
train = optimizer.minimize(loss)

init = tf.global_variables_initializer()



# 세션 활성화
sess = tf.Session()
sess.run(init)

print("start")
for i in range(1, 11):
    for j in range(1, 500):
        batch_range_st = (j-1)*100
        batch_range_fi = j*100
        train_xs, train_ys = loader2.next_batch(trainX, trainY, batch_range_st, batch_range_fi)
        sess.run(train, feed_dict = {x_load : train_xs, z_onehot: train_ys, keep_prob : 0.9})
    train_acc = sess.run(accuracy, \
                         feed_dict = {x_load : train_xs, z_onehot : train_ys, keep_prob : 1.0})
    print('train %d 에폭 정확도'%i, train_acc)
    test_xs, test_ys =loader2.next_batch(testX, testY, 0, 100)
    test_acc = sess.run(accuracy, \
                        feed_dict = {x_load : test_xs, z_onehot : test_ys, keep_prob : 1.0})
    print('test  %d 에폭 정확도'%i, test_acc)
    print('+=====================+')

sess.close()













■ 개 / 고양이 이미지 분류

 * 개고양이 분류 데이터 전처리 함수 4가지
	 1. image_load
	 2. label_load
	 3. next_batch
	 4. shuffle_batch




문제 67. 개 고양이 사진이 있는 폴더를 만들고 그 폴더에 개사진 100장과 고양이 사진 100장을 넣고 아래와 
	 같이 불러오는 함수를 생성하시오 !

	import os
	import numpy as np
	import cv2
	
	test_image = "c:\\b\\catdog"
	
	def image_load(path):
	    file_list = os.listdir(path)
	    for i in range(len(file_list)):
	        file_list[i] = int(file_list[i][1:-6])
	    file_list.sort()
	    for i in range(len(file_list)):
	        file_list[i] = path + "\\" + str(file_list[i]) + ".jpeg"
	    image =[]
	    for i in file_list:
	        img = cv2.imread(i)
	        image.append(img)
	    image = np.array(image)
	    return file_list
	
	print(image_load(test_image))




문제 68. 

	import numpy as np
	import csv
	
	test_label = "c:\\b\\cat_dog_label.csv"
	
	def label_load(path):
	    file = open(path)
	    labeldata = csv.reader(file)
	    labellist = []
	    for i in labeldata:
	        labellist.append(i)
	    labellist = np.array(labellist).astype(int)
	    labellist = np.eye(2)[labellist]
	    return np.squeeze(labellist, axis = 1)
	
	print(label_load(test_label))
	




문제 69 위의 4개의 함수를 loader3.py로 생성해서 아래와 같이 실행되게 해보시오 !

	import loader3
	
	
	train_image = "c:\\b\\train_4000"
	train_label = "c:\\b\\train_label_4000.csv"
	
	print("LOADING DATA")
	trainX = loader3.image_load(train_image)
	print(trainX.shape)
	trainY = loader3.label_load(train_label)
	print(trainY.shape)



